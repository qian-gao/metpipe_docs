# Introduction

This section describes recommended **computational best practices** for LC–MS-based **metabolomics and lipidomics** data processing. The focus is on producing **reproducible, well-documented, and quality-controlled** datasets suitable for downstream statistics and interpretation.

## What this section covers

### General guidelines
- **Sample randomization** prior to data acquisition (to reduce confounding by run order)
- **Quality control (QC) samples**: types, placement, and how to use QC results
- **Data conversion** and file-format considerations before processing
- **LC–MS data structure**: samples, batches, injections, and metadata needed for analysis

### Untargeted data processing
- **Retention time prediction/mapping** (as applicable)
- **Internal-standard and other QC** and diagnostic checks
- **Pre-processing** (e.g., filtering, transformation, initial normalization choices)
- **Peak grouping** and consolidation across samples
- **Peak cleaning** (removal of unstable/noisy features)
- **Missing-value imputation** (when appropriate, with assumptions stated)
- **Normalization** and batch-effect handling
- **Merging peak lists** and generating peak tables




